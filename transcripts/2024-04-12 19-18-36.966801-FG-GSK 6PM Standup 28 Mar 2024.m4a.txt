Alright, can we get started? Hello everybody. Yes, sure. Alright, Brian do you want to get us started? Yeah, get started. Still working through testing. I need to create another copy of the data on demand endpoint for the enrichment graph part right now. It's just loading the test export which is loading the data that I think Shruti provided. So I need to make another copy of that data on demand endpoint. I've copied the Python scripts for the fast API over the server. I'm able to run it through HTTP but not HTTPS without some certs. I think we can reuse the same certs we applied for Anzu, but I'll have to look into that. I also need to get that set up so it runs in the background for fast API. After that's done, should be done shortly. I'm just going to connect everything together so that Anzu is reading the results of the fast API and can present those in a dashboard. That's it for my update. It's kind of spread across all of the different tickets for the API testing. That makes sense. Do we have any questions for Brian? Alright. Kundan, do you want to go next? Yes, Prathamesh. Today, I worked on these last two tickets in progress. I worked on data bricks and I was able to read data from CDM and I also created temp table just to copy data. This one somewhat is now done. This credential that we are using, client-secret and client-id, that is provided by CDM team, but we have already replaced it. Me, Manju and Mark sat together and created client-id and secret and we have this support ticket for that. I think you can move it to done. The purpose of this is solved. We are able to read data. Once I am back, I will work on creating a pipeline to read data. Can you go to the next task? Support team has mounted existing NFS on new servers. I will set with Brian and Sanjay to update existing configuration so that our existing data is moved to the new server. That's it. You can mention here that NFS mounting is done. What would be the next task for this one? Updating configurations so that we are able to read existing data. Thank you. Do we have any questions for Kunal? Varsha, Rohit, do you want to go ahead with the updates? Yes, Prathamesh. We have worked on the presentation for the deck. We had also created a story in the afternoon today. If you open that story, which has been assigned to Rohit. I guess. The first one, I think you have already sent an invite, right? Yes. Can we mark this done? We have sent an invite for Thursday, right? Yes, Thursday. Okay. Do we want to record any update over here? No. We can paste the link over here, right? Yes, we can add the link of that. Do we have any questions for Varsha and Rohit? Shruti, do you want to go next? Can you come down? There is one more task, right? Yes, this one. Final relationships for this. We had a call with the Solbromaine team and they helped us out with the remaining few doubts which we had regarding the bridging columns. So, now, whatever they have given me, I would be again looking into it and then updating our map. This is the update for this particular task. Yes, Prathamesh. Maybe I will update this here. Okay. So, we can say from this last update, just to have some record over here, we have the Is this comment correct? Yes, we have the broad data, broad Rx data, supply chain Rx data. Okay. Okay, there is some confusion going on. Can you just come down? Synthetic data for testing APF. So, Brian, I just wanted to ask that I had shared a link of the file where we have made some dummy data plus some realistic data for regulatory and supply chain. So, did you have a look and was that useful? Because this is still in progress. Yes, that was very useful. I think it's already being ingested, that file, into ANZO. Okay. So, it's being used for the testing and that's working for the APIs as well. So, I put the data on demand endpoints, point to those test file. So, if you can go again to the acceptance criteria, Prathamesh. Brian, do you think that based on examples, create more test data that's synthetic, not real? So, Brian, do you think anything more to be added into that file or that was a file? Because I would be adding a few more examples maybe in a day or two. Because we have a demo next week scheduled and maybe a few more examples pertaining to procedure types would be added to that. So, any more columns to be added? No, I don't think so. I think it's good right now. Okay, Prathamesh. Do we have any other questions for Shruti? Alright. Do we have anything to discuss for the parking lot? Alright, thank you everybody. Bye-bye. Have a great day. Brian, can we continue on this call or you want to connect after at 7pm? We can continue on this call. Sure, okay. Thank you everyone. Thank you all. Bye-bye.