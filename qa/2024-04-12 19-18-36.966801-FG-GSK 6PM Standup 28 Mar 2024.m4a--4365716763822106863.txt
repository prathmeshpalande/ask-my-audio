
                transcript = "Alright, can we get started? Hello everybody. Yes, sure. Alright, Brian do you want to get us started? Yeah, get started. Still working through testing. I need to create another copy of the data on demand endpoint for the enrichment graph part right now. It's just loading the test export which is loading the data that I think Shruti provided. So I need to make another copy of that data on demand endpoint. I've copied the Python scripts for the fast API over the server. I'm able to run it through HTTP but not HTTPS without some certs. I think we can reuse the same certs we applied for Anzu, but I'll have to look into that. I also need to get that set up so it runs in the background for fast API. After that's done, should be done shortly. I'm just going to connect everything together so that Anzu is reading the results of the fast API and can present those in a dashboard. That's it for my update. It's kind of spread across all of the different tickets for the API testing. That makes sense. Do we have any questions for Brian? Alright. Kundan, do you want to go next? Yes, Prathamesh. Today, I worked on these last two tickets in progress. I worked on data bricks and I was able to read data from CDM and I also created temp table just to copy data. This one somewhat is now done. This credential that we are using, client-secret and client-id, that is provided by CDM team, but we have already replaced it. Me, Manju and Mark sat together and created client-id and secret and we have this support ticket for that. I think you can move it to done. The purpose of this is solved. We are able to read data. Once I am back, I will work on creating a pipeline to read data. Can you go to the next task? Support team has mounted existing NFS on new servers. I will set with Brian and Sanjay to update existing configuration so that our existing data is moved to the new server. That's it. You can mention here that NFS mounting is done. What would be the next task for this one? Updating configurations so that we are able to read existing data. Thank you. Do we have any questions for Kunal? Varsha, Rohit, do you want to go ahead with the updates? Yes, Prathamesh. We have worked on the presentation for the deck. We had also created a story in the afternoon today. If you open that story, which has been assigned to Rohit. I guess. The first one, I think you have already sent an invite, right? Yes. Can we mark this done? We have sent an invite for Thursday, right? Yes, Thursday. Okay. Do we want to record any update over here? No. We can paste the link over here, right? Yes, we can add the link of that. Do we have any questions for Varsha and Rohit? Shruti, do you want to go next? Can you come down? There is one more task, right? Yes, this one. Final relationships for this. We had a call with the Solbromaine team and they helped us out with the remaining few doubts which we had regarding the bridging columns. So, now, whatever they have given me, I would be again looking into it and then updating our map. This is the update for this particular task. Yes, Prathamesh. Maybe I will update this here. Okay. So, we can say from this last update, just to have some record over here, we have the Is this comment correct? Yes, we have the broad data, broad Rx data, supply chain Rx data. Okay. Okay, there is some confusion going on. Can you just come down? Synthetic data for testing APF. So, Brian, I just wanted to ask that I had shared a link of the file where we have made some dummy data plus some realistic data for regulatory and supply chain. So, did you have a look and was that useful? Because this is still in progress. Yes, that was very useful. I think it's already being ingested, that file, into ANZO. Okay. So, it's being used for the testing and that's working for the APIs as well. So, I put the data on demand endpoints, point to those test file. So, if you can go again to the acceptance criteria, Prathamesh. Brian, do you think that based on examples, create more test data that's synthetic, not real? So, Brian, do you think anything more to be added into that file or that was a file? Because I would be adding a few more examples maybe in a day or two. Because we have a demo next week scheduled and maybe a few more examples pertaining to procedure types would be added to that. So, any more columns to be added? No, I don't think so. I think it's good right now. Okay, Prathamesh. Do we have any other questions for Shruti? Alright. Do we have anything to discuss for the parking lot? Alright, thank you everybody. Bye-bye. Have a great day. Brian, can we continue on this call or you want to connect after at 7pm? We can continue on this call. Sure, okay. Thank you everyone. Thank you all. Bye-bye."

                question = "Summarize this office's daily standup call. This may be an inaccurate transcript. Generate action items."

                response = "Summary of Daily Standup Call:\n\nDuring the daily standup call, team members provided updates on their current tasks and discussed the next steps for their projects. \n\n1. **Brian's Update**: Brian is working on creating a copy of the data on demand endpoint for the enrichment graph. He has successfully copied Python scripts for the Fast API over to the server and is troubleshooting HTTPS connectivity issues, considering reusing certificates from a previous project (Anzu). He plans to ensure the Fast API runs in the background and aims to integrate it with Anzu for dashboard presentation. His work spans across multiple API testing tickets.\n\n2. **Kundan's Update**: Kundan reported progress on two tickets involving Databricks and data access from CDM, including the creation of a temporary table for data copying. With the help of Manju and Mark, client credentials were updated, and a support ticket was resolved. Kundan plans to focus on creating a pipeline for data reading upon his return. Additionally, NFS mounting on new servers has been completed, and Kundan will work with Brian and Sanjay to update configurations for data access.\n\n3. **Varsha and Rohit's Update**: They have worked on a presentation deck and created a story for an upcoming meeting on Thursday. They plan to add a link to the story for reference.\n\n4. **Shruti's Update**: Shruti discussed finalizing relationships with the Solbromaine team and plans to update the mapping based on the feedback received. She also inquired about the usefulness of the synthetic and realistic data provided for testing, which Brian confirmed was ingested into Anzu and being used for API testing.\n\nAction Items:\n\n1. **Brian**:\n   - Resolve HTTPS connectivity issues for the Fast API.\n   - Ensure Fast API runs in the background.\n   - Integrate Fast API with Anzu for dashboard presentation.\n\n2. **Kundan**:\n   - Work on creating a data reading pipeline.\n   - Update configurations with Brian and Sanjay for accessing data on new servers.\n\n3. **Varsha and Rohit**:\n   - Add the meeting link to the story for Thursday's presentation.\n\n4. **Shruti**:\n   - Update the mapping based on feedback from the Solbromaine team.\n   - Add more examples to the synthetic data file for next week's demo, focusing on procedure types.\n\nThe team plans to continue discussions on specific tasks after the call, with Brian and another team member agreeing to continue their discussion immediately following the standup."
            